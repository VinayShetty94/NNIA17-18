{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Sheet 1:  Hands-on Linear Regression (deadline: 31 Oct, 14:00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this first exercise sheet is to make you familiar with **jupyter notebook** which we will use to run part of the exercises in this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do so you have to implement a very naive algorithm to solve a **linear regression** problem: **Grid Search**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is one of the simplest and also most widely used machine learning algorithms. It is used to model the relationship between a dependent variable $y$ and one or more independent (also called explanatory) variables $x$. Here, we will focus on the case where we just have a single indepenedent variable, so-called **simple linear regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given some inputs $x = \\{x_0, \\dots, x_n\\}$ and corresponding outputs $y = \\{y_0, \\dots, y_n\\}$. Linear regression assumes that there exists an (unknown!) linear relationship between the input and the output, i.e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = f(x) = \\beta_0 + \\beta_1x + \\epsilon$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\epsilon$ is an unobserved noise variable. This relationship is approximated as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{y} = \\hat{f}(x; w_0, w_1) = w_0 + w_1x$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the goal of linear regression is to estimate the unknown parameters $w_0$ and $w_1$ such that the error between the model prediction $\\hat{y}$ and the true output $y$ is minimized. Formaly, let the ith **residual** be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$r_i = y_i - \\hat{f}(x_i; w_0, w_1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.e. the difference between the ith output and the ith prediction and let"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$S = \\sum\\limits_{i=1}^n r_i^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "be the sum of squared residuals. Then one tries to find the paramaters $w_0$ and $w_1$ that minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$MSE = \\frac{1}{n}~S$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the so called **mean squared error**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Exercise: Fitting a Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will implement several functions which will help you to fit a simple linear regression model on training data using grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before you start:**\n",
    "- Make sure that you use numpy arrays instead of python lists.\n",
    "- You can assume that all vectors are column vectors not row vectors.\n",
    "- Hint: Try to vectorize as much of your computations as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Implement a loss function which measures the average squared difference between the true data and the model prediction, i.e the mean squared error (MSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points: 1.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will make use of numpy to vectorize most of the computations\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(y, prediction):\n",
    "    \"\"\"\n",
    "    :param y: The true outputs\n",
    "    :param prediction: The predictions of your model\n",
    "    :return: The MSE between the model predictions and the true outputs\n",
    "    \"\"\"\n",
    "    # TODO: implement\n",
    "    # this is really a forward implementation of MSE.\n",
    "    r = y - prediction;\n",
    "    return (np.sum(np.square(r)))/ len(r);\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Implement a function which describes a linear relationship between the input and output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points: 0.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_model(intercept, slope, x):\n",
    "    \"\"\"\n",
    "    :param intercept: The model intercept\n",
    "    :param slope: The model slope\n",
    "    :return: The model prediction on x\n",
    "    \"\"\"\n",
    "    # TODO: implement\n",
    "    # forward implementation of the linear model\n",
    "    # where y = slope * x + intercept\n",
    "    #print (\"dot product result : \")\n",
    "    #print ( np.dot(slope, x))\n",
    "    return (x*slope)+ intercept;\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Given different values for the slope and the intercept of your model. Implement a function which returns those that result in the best fit, i.e. minimizes the difference between the true data and the model prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points: 4.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search(intercepts, slopes, x, y):\n",
    "    \"\"\"\n",
    "    :param intercepts: A numpy array of different intercepts\n",
    "    :param slopes: A numpy array of different slopes\n",
    "    :param x: The inputs\n",
    "    :param y: The true outputs\n",
    "    :return (intercept, slope): The intercept and slope that result in the best fit\n",
    "    \"\"\"\n",
    "    # TODO: implement\n",
    "    # we declare a min_value, search for it in the loss matrix of all intercepts and slopes and then\n",
    "    # get the indices to get the perfect intercept and slope for the model\n",
    "    min_value=sys.maxsize;\n",
    "    \n",
    "    slope_index=0;\n",
    "    intercept_index=0;\n",
    "    for i in range(slopes.size) :\n",
    "        for j in range (intercepts.size):\n",
    "            pred=linear_model(intercepts[j],slopes[i],x);\n",
    "            mvalue=loss(y,pred);\n",
    "            if mvalue<min_value:\n",
    "                min_value=mvalue;\n",
    "                slope_index=i;\n",
    "                intercept_index=j;\n",
    "    return (intercepts[intercept_index],slopes[slope_index]);\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: Fit a linear model over some training data and plot the resulting model using matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points: 1.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will use the datasets functionality provided by sklearn to generate some training data\n",
    "from sklearn.datasets import make_regression, make_classification\n",
    "\n",
    "# Let's create some training data to fit our model on\n",
    "x_train, y_train = make_regression(n_samples=50, n_features=1, n_informative=1, noise=30.0)\n",
    "y_train = y_train[:, None] #  make y a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the test data on which we want to evaluate our fitted model\n",
    "x_test = np.linspace(start=-4, stop=4, num=20)\n",
    "x_test = x_test[:, None] #  make x_test a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are the different values for the intercept and slope on which we want to perform a gridsearch\n",
    "intercepts = np.linspace(start=-10.0, stop=10.0, num=50)\n",
    "intercepts = intercepts[:, None] #  make intercepts a column vector\n",
    "slopes = np.linspace(start=0.0, stop=100.0, num=50)\n",
    "slopes = slopes[:, None] #  make slopes a column vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write code to fit a linear model on $x_{train}$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 2.65306122]), array([ 32.65306122]))\n"
     ]
    }
   ],
   "source": [
    "# TODO: fit a linear model on x_train\n",
    "# apply grid search on the training data to get the parameters and then use the parameters obtained \n",
    "#to predict the values of test data\n",
    "x_model = grid_search(intercepts, slopes, x_train, y_train)\n",
    "y_predicted=linear_model(x_model[0],x_model[1],x_test);\n",
    "print (x_model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complete the code below to plot the training data together with the fitted linear model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n00CglFIx7v8B+EBPikubUXQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a66a2ff080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a matplotlib figure for the training data and our fitted linear regression model\n",
    "fig, axes = plt.subplots(1, 1)\n",
    "axes.scatter(x_train, y_train, color='blue', marker='.', alpha=.6, s=2e2, label='Training Data')\n",
    "axes.plot(x_test,y_predicted, color='red', ls='-', label='Linear Model')\n",
    "axes.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5: Run the code above several times. Each time the generated data will be different. How would you interpret the result? Is the obtained fit good enough? What are disadvantages of the grid search approach and what could be other (better) ways of fitting a linear model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Points: 3.0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *( The model that fits the training data doesn't always fit the test data. One reason for that could be that the training data and test data have different distributions.)*\n",
    "- *(Not really, since it could be that x_train (train data) and x_test(test data) have different distributions )*\n",
    "- *(Disadvantage of grid_search is using brute force to check all possible answers,, if intercepts and slopes are of dimension 10^3 then the complexity is really high and expensive)*\n",
    "- *(The search for hyperparameters can be done using gradient descent algorithm. We initialize first the parameters (intercepts, slopes) with random values and then solve MSE as an optimization problem argmin (intercepts, slopes) = 1/m * sum(y - predicted_value)^2 , where m is the number of data points. By fixing one variable and solving for the other, we take the derivation of MSE, we can search for intercepts and slopes value that give us the best fit. Hence, we should use a learning rate as a parameter. Intercepts and slopes would be updated with respect to all the data points at a time which could be computationally expensive, thus we can use stochastic gradient descent (SGD),  where intercepts and slopes would be updated with respect to each data point at a time. Thus we will need only m iteration to get the parameters. Though SGD doesn't get a perfect fit, but it still gets a good approximation of the parameters.)*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions\n",
    "You should provide a single Jupyter notebook as a solution. The naming should include the assignment number and matriculation IDs of all team members in the following format:\n",
    "**assignment-1_matriculation1_matriculation_2_matriculation3.ipynb** (in case of 3 team members). \n",
    "Make sure to keep the order matriculation1_matriculation_2_matriculation3 the same for all assignments.\n",
    "\n",
    "Please, submit your solution to your tutor (with **[NNIA][assignment-1]** in email subject):\n",
    "1. Maksym Andriushchenko s8mmandr@stud.uni-saarland.de\n",
    "2. Marius Mosbach s9msmosb@stud.uni-saarland.de\n",
    "3. Rajarshi Biswas rbisw17@gmail.com\n",
    "\n",
    "**If you are in a team, please submit only 1 solution to only 1 tutor.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
